would anyone be <unk> to look over my simple nn <unk> code ? i 'm currently taking the stanford ml course on coursera and have been more or less <unk> through all the programming <unk> . this <unk> neural networks and the <unk> algorithm . however , i tried <unk> it on my own from memory and i just ca n't get it to work right . first i tried in java , then in <unk> , and i 'm getting similar results - a bit of learning at first and then it <unk> off at a low <unk> <unk> . obviously something is wrong ( probably in my <unk> algorithm ) , but i 've been over and over it and ca n't figure out what . there are no errors when i run the code , but i 'm thinking it has to be something obvious that i 'm <unk> . would anyone be <unk> to take a look at some <unk> <unk> <unk> code to see if anything looks wrong ? code is [ here ] ( https : <unk> ) . <eoq> if you still need to <unk> it , have a look at : http : <unk> <unk> <eoa> 
problem : <unk> a <unk> <unk> that outputs numbers from <unk> . so i <unk> recently <unk> into statistical <unk> and this problem <unk> into my head . so here s the rest of the setup : the <unk> outputs a list like : <unk> , <unk> , 32 without <unk> and no <unk> so <unk> to my <unk> this can be thought of as the <unk> <unk> and <unk> model and so the whole theory of hidden markov models can be used to <unk> a solution to this problem . so what i 'd like is <unk> that yes i m on the right track with a solution to this and also what software should i use to actually try and solve this . <eoq> when i first read your problem i thought of hidden markov models . another approach may be recurrent neural networks . <eoa> 
common <unk> for beginners ? my <unk> is <unk> <unk> . i 'm getting into machine learning , and tried implementing a neural net in java based off of [ this ] ( http : <unk> ) online book . i 've tested two different training scenarios - one was simply adding two numbers between 0 and <unk> together , and the other was <unk> <unk> <unk> from the mnist data set . the problem is convergence is <unk> and <unk> out at a fairly low level ( <unk> % correct answers for addition and <unk> % for mnist data ) . it 's obviously working <unk> because i 'm getting more correct answers than i would by chance alone , but i feel like i should be getting a lot more . the addition problem is easy and the book <unk> a python implementation getting over <unk> % correct after a single training epoch . <unk> learning rate and <unk> of hidden layers has n't <unk> much ( also i feel like i need to have a pretty high learning rate for things to get <unk> , like <unk> ) . i 've been over and over my backpropagation algorithm many times and ca n't find any <unk> . is there anything obvious i may have <unk> or should <unk> ? any help would be much appreciated . <eoq> you may want to try the <unk> tutorial 's <unk> for <unk> your feed-forward network code : <eoa> 
common <unk> for beginners ? my <unk> is <unk> <unk> . i 'm getting into machine learning , and tried implementing a neural net in java based off of [ this ] ( http : <unk> ) online book . i 've tested two different training scenarios - one was simply adding two numbers between 0 and <unk> together , and the other was <unk> <unk> <unk> from the mnist data set . the problem is convergence is <unk> and <unk> out at a fairly low level ( <unk> % correct answers for addition and <unk> % for mnist data ) . it 's obviously working <unk> because i 'm getting more correct answers than i would by chance alone , but i feel like i should be getting a lot more . the addition problem is easy and the book <unk> a python implementation getting over <unk> % correct after a single training epoch . <unk> learning rate and <unk> of hidden layers has n't <unk> much ( also i feel like i need to have a pretty high learning rate for things to get <unk> , like <unk> ) . i 've been over and over my backpropagation algorithm many times and ca n't find any <unk> . is there anything obvious i may have <unk> or should <unk> ? any help would be much appreciated . <eoq> you should be getting a lot more . if you are doing the same number of iterations as that online book , you should be getting the same results . for a similar <unk> , you can get up to <unk> % accuracy on mnist ( <unk> http : <unk> ) . you clearly have a <unk> . i would write unit <unk> for the pieces until you find it . good luck ! <eoa> 
the <unk> course was my <unk> <eoa> 
i think the [ unsupervised feature learning and deep learning tutorial ] ( http : <unk> ) is a good follow up . <eoa> 
study note <unk> hi <unk> . should start out by saying that i am new to ml . i have a <unk> background in stats and <unk> , but none in programming ( i 'll be taking the coursera class in programming this <unk> ) . for a while now , i 've had an idea for a program <unk> been <unk> around in my head . specifically , i want to create a program that takes text ( likely in <unk> or <unk> <unk> ) and <unk> it into a series of questions and answers . for example , given the following : > <unk> the <unk> of <unk> is <unk> . > <unk> into <unk> & a <unk> <unk> : what is the <unk> of <unk> ? a : what <unk> of <unk> is <unk> . any suggestions for starting this would be greatly appreciated . i know there are a lot of courses out there , but if someone could <unk> down what areas i should focus on , then i could take a <unk> approach to learning about what i need to know . thanks ! <eoq> two quick <unk> . first , you would probably want to deal with raw text rather than <unk> <unk> . there are tools to extract text from <unk> and pdf files , but they are error <unk> . second , this is n't so much a machine learning task as it is a <unk> task . see any good <unk> <unk> on the topic of <unk> <unk> , and you 'll see that there 's most likely a simple <unk> solution to this problem . <eoa> 
difficulty training simple xor function . i 've <unk> a neural network , with the following structure : <unk> - <unk> - <unk> layer** . <unk> - <unk> - <unk> layer** . 3 weights per node ( one for bias ) . <unk> - <unk> layer** . 3 weights ( one for bias ) . i am trying to train it the xor function with the following test data : * **0 1** - desired result : **1** * **1 0** - desired result : **1** * **0 0** - desired result : **0** * **1 1** - desired result : **0** after training , the <unk> square <unk> of test ( when looking for a 1 result ) { 0 , 1 } = 0 , which is good i <unk> . however the mean square error of test ( when looking for a 0 result ) { 1 , 1 } = 0.5 , which <unk> needs to be zero ? during the train stage i <unk> the mse of true results <unk> to zero very quickly , <unk> mse of false results <unk> around 0.5 . i 'm using back propagation to train the network , with a sigmoid function . the issue is that when i test any combination after the training , i get a <unk> result of <unk> for <unk> , and <unk> for <unk> . i 'm trying to get 1 for true , 0 for false . the network seems to learn very fast , even with an extremely small learning rate . if it helps , here is the weights that are <unk> , with a learning rate of <unk> : <unk> = <unk> , <unk> = <unk> , <unk> = <unk> ( **bias weight** ) - hidden layer <unk> = <unk> , <unk> = <unk> , <unk> = <unk> ( **bias weight** ) - hidden layer <unk> = <unk> , <unk> = <unk> , <unk> = <unk> ( **bias weight** ) - output node back propagation steps : 1 . <unk> forward a feature set , <unk> the weights x input set . calculating sigmoid per node . ** 2 . <unk> bias . ** 3 . <unk> output node error , desired output - actual output ( sigmoid ) . ** 4 . <unk> <unk> error , layer above error x <unk> weight . per node . ** 5 . <unk> weights , <unk> <unk> mse low enough . ** apologies for the long post , but i 've been <unk> my <unk> over this for <unk> now , and i ca n't determine what is wrong with my back propagation algorithm . thanks in advance . <eoq> can you show me your code ? its <unk> what order you 're doing some of the steps in the feed-forward process . and also you need to <unk> through the whole network . <eoa> 
difficulty training simple xor function . i 've <unk> a neural network , with the following structure : <unk> - <unk> - <unk> layer** . <unk> - <unk> - <unk> layer** . 3 weights per node ( one for bias ) . <unk> - <unk> layer** . 3 weights ( one for bias ) . i am trying to train it the xor function with the following test data : * **0 1** - desired result : **1** * **1 0** - desired result : **1** * **0 0** - desired result : **0** * **1 1** - desired result : **0** after training , the <unk> square <unk> of test ( when looking for a 1 result ) { 0 , 1 } = 0 , which is good i <unk> . however the mean square error of test ( when looking for a 0 result ) { 1 , 1 } = 0.5 , which <unk> needs to be zero ? during the train stage i <unk> the mse of true results <unk> to zero very quickly , <unk> mse of false results <unk> around 0.5 . i 'm using back propagation to train the network , with a sigmoid function . the issue is that when i test any combination after the training , i get a <unk> result of <unk> for <unk> , and <unk> for <unk> . i 'm trying to get 1 for true , 0 for false . the network seems to learn very fast , even with an extremely small learning rate . if it helps , here is the weights that are <unk> , with a learning rate of <unk> : <unk> = <unk> , <unk> = <unk> , <unk> = <unk> ( **bias weight** ) - hidden layer <unk> = <unk> , <unk> = <unk> , <unk> = <unk> ( **bias weight** ) - hidden layer <unk> = <unk> , <unk> = <unk> , <unk> = <unk> ( **bias weight** ) - output node back propagation steps : 1 . <unk> forward a feature set , <unk> the weights x input set . calculating sigmoid per node . ** 2 . <unk> bias . ** 3 . <unk> output node error , desired output - actual output ( sigmoid ) . ** 4 . <unk> <unk> error , layer above error x <unk> weight . per node . ** 5 . <unk> weights , <unk> <unk> mse low enough . ** apologies for the long post , but i 've been <unk> my <unk> over this for <unk> now , and i ca n't determine what is wrong with my back propagation algorithm . thanks in advance . <eoq> the bias is just another input to the neuron . do n't <unk> it <unk> ( besides always getting an input value = 1 ) . also , does your code work for the or and and cases ? <eoa> 
difficulty training simple xor function . i 've <unk> a neural network , with the following structure : <unk> - <unk> - <unk> layer** . <unk> - <unk> - <unk> layer** . 3 weights per node ( one for bias ) . <unk> - <unk> layer** . 3 weights ( one for bias ) . i am trying to train it the xor function with the following test data : * **0 1** - desired result : **1** * **1 0** - desired result : **1** * **0 0** - desired result : **0** * **1 1** - desired result : **0** after training , the <unk> square <unk> of test ( when looking for a 1 result ) { 0 , 1 } = 0 , which is good i <unk> . however the mean square error of test ( when looking for a 0 result ) { 1 , 1 } = 0.5 , which <unk> needs to be zero ? during the train stage i <unk> the mse of true results <unk> to zero very quickly , <unk> mse of false results <unk> around 0.5 . i 'm using back propagation to train the network , with a sigmoid function . the issue is that when i test any combination after the training , i get a <unk> result of <unk> for <unk> , and <unk> for <unk> . i 'm trying to get 1 for true , 0 for false . the network seems to learn very fast , even with an extremely small learning rate . if it helps , here is the weights that are <unk> , with a learning rate of <unk> : <unk> = <unk> , <unk> = <unk> , <unk> = <unk> ( **bias weight** ) - hidden layer <unk> = <unk> , <unk> = <unk> , <unk> = <unk> ( **bias weight** ) - hidden layer <unk> = <unk> , <unk> = <unk> , <unk> = <unk> ( **bias weight** ) - output node back propagation steps : 1 . <unk> forward a feature set , <unk> the weights x input set . calculating sigmoid per node . ** 2 . <unk> bias . ** 3 . <unk> output node error , desired output - actual output ( sigmoid ) . ** 4 . <unk> <unk> error , layer above error x <unk> weight . per node . ** 5 . <unk> weights , <unk> <unk> mse low enough . ** apologies for the long post , but i 've been <unk> my <unk> over this for <unk> now , and i ca n't determine what is wrong with my back propagation algorithm . thanks in advance . <eoq> i just <unk> xor on a <unk> nn and got these weights h1 h2 <unk> <unk> <unk> <unk> weight <unk> <unk> <unk> <unk> to input 1 <unk> <unk> <unk> <unk> to input 2 <unk> <unk> <unk> <unk> weight <unk> <unk> <unk> to h1 <unk> <unk> <unk> to h2 <unk> these numbers into your code to see if your forward propagation code works . results that i get using sigmoid units are : <unk> <unk> result for 0 0 <unk> <unk> result for 0 1 <unk> <unk> result for 1 0 <unk> <unk> result for 1 1 <eoa> 
neural network learning fast , giving me false positives . i 've recently started implementing a feed-forward neural network and i 'm using <unk> as the learning method . i 've been using http : <unk> as a guide . however , after just the first epoch , my <unk> is 0** . before using the network for my real purpose i 've tried with the simple network structure : * 4 binary inputs , 1 , 1 , 0 , 0 . * 2 hidden layers , 4 neurons each . * 1 output neuron , 1.0 should = <unk> input . each training epoch runs the test input ( 1 , 1 , 0 , 0 ) , <unk> the output error ( sigmoid derivative * ( 1.0 - sigmoid ) ) , back <unk> the error and finally <unk> the weights . each neuron 's new weight = <unk> + <unk> * the neuron 's error * the input to the weight . ** each hidden neuron 's error = ** ( sum of all output neuron 's error * connected weight ) * the neuron 's sigmoid derivative . ** the issue is that my <unk> rate has to be <unk> for me to see any sort of <unk> ' between the epochs in terms of <unk> the error . in this case , the error <unk> around <unk> . any <unk> learning rate and the error results in 0 after the first pass , and thus results in <unk> <unk> . also when i try this network with my real data ( a set of 32 audio features from sample - 32 neurons per hidden layer ) - i get the same issue . to the point where any noise will <unk> a false positive . possibly this could be an input feature issue , but as i 'm testing using a high pitch note i can clearly see the raw data <unk> from a low pitch one . i 'm a neural networks newbie , so i 'm almost positive the issue is with my network . any help would be greatly appreciated . <eoq> i really do n't know enough to say for sure but it sounds like you are just overfitting . nns are very good at that . try using a smaller network or some other <unk> method . <eoa> 
neural network learning fast , giving me false positives . i 've recently started implementing a feed-forward neural network and i 'm using <unk> as the learning method . i 've been using http : <unk> as a guide . however , after just the first epoch , my <unk> is 0** . before using the network for my real purpose i 've tried with the simple network structure : * 4 binary inputs , 1 , 1 , 0 , 0 . * 2 hidden layers , 4 neurons each . * 1 output neuron , 1.0 should = <unk> input . each training epoch runs the test input ( 1 , 1 , 0 , 0 ) , <unk> the output error ( sigmoid derivative * ( 1.0 - sigmoid ) ) , back <unk> the error and finally <unk> the weights . each neuron 's new weight = <unk> + <unk> * the neuron 's error * the input to the weight . ** each hidden neuron 's error = ** ( sum of all output neuron 's error * connected weight ) * the neuron 's sigmoid derivative . ** the issue is that my <unk> rate has to be <unk> for me to see any sort of <unk> ' between the epochs in terms of <unk> the error . in this case , the error <unk> around <unk> . any <unk> learning rate and the error results in 0 after the first pass , and thus results in <unk> <unk> . also when i try this network with my real data ( a set of 32 audio features from sample - 32 neurons per hidden layer ) - i get the same issue . to the point where any noise will <unk> a false positive . possibly this could be an input feature issue , but as i 'm testing using a high pitch note i can clearly see the raw data <unk> from a low pitch one . i 'm a neural networks newbie , so i 'm almost positive the issue is with my network . any help would be greatly appreciated . <eoq> <unk> your initial weights . i 've had good results with random numbers between <unk> 0.5 <eoa> 
neural network learning fast , giving me false positives . i 've recently started implementing a feed-forward neural network and i 'm using <unk> as the learning method . i 've been using http : <unk> as a guide . however , after just the first epoch , my <unk> is 0** . before using the network for my real purpose i 've tried with the simple network structure : * 4 binary inputs , 1 , 1 , 0 , 0 . * 2 hidden layers , 4 neurons each . * 1 output neuron , 1.0 should = <unk> input . each training epoch runs the test input ( 1 , 1 , 0 , 0 ) , <unk> the output error ( sigmoid derivative * ( 1.0 - sigmoid ) ) , back <unk> the error and finally <unk> the weights . each neuron 's new weight = <unk> + <unk> * the neuron 's error * the input to the weight . ** each hidden neuron 's error = ** ( sum of all output neuron 's error * connected weight ) * the neuron 's sigmoid derivative . ** the issue is that my <unk> rate has to be <unk> for me to see any sort of <unk> ' between the epochs in terms of <unk> the error . in this case , the error <unk> around <unk> . any <unk> learning rate and the error results in 0 after the first pass , and thus results in <unk> <unk> . also when i try this network with my real data ( a set of 32 audio features from sample - 32 neurons per hidden layer ) - i get the same issue . to the point where any noise will <unk> a false positive . possibly this could be an input feature issue , but as i 'm testing using a high pitch note i can clearly see the raw data <unk> from a low pitch one . i 'm a neural networks newbie , so i 'm almost positive the issue is with my network . any help would be greatly appreciated . <eoq> sounds like it 's overfitting the training data ... have you tried adding a regularization term to your cost function ? <eoa> 
how much data do you need to do ml ? i 'm <unk> most familiar with split testing on <unk> . but to really do some ml , what kind of data sets do you need ? <eoq> the <unk> answer is that it <unk> . the more complicated your model is the more data you need in order to <unk> <unk> . i 've [ read ] ( http : <unk> ? <unk> & <unk> & <unk> & <unk> ) that a good rule of <unk> for a supervised linear model is <unk> training examples for every parameter of the model . it is my understanding that linear models are generally considered relatively simple models so that number should probably increase for other <unk> of models . <eoa> 
<unk> neural network does not converge . hello , i 'm trying to <unk> the <unk> neural network . i 'm having trouble getting my network to converge . it 'll get close , but there is always one output that wo n't converge . for example : output = <unk> 0.0000 <unk> 0.0000 0.0000 <unk> <unk> <unk> 0.0000 <unk> <unk> 0.0000 0.0000 <unk> 0.0000 0.0000 <unk> <unk> <unk> 0.0000 <unk> <unk> 0.0000 0.0000 0.0000 <unk> 0.0000 <unk> 0.0000 <unk> 0.0000 0.0000 0.0000 0.0000 <unk> <unk> <unk> <unk> 0.0000 0.0000 <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> 0.0000 0.0000 0.0000 0.0000 <unk> <unk> 0.0000 <unk> 0.0000 0.0000 0.0000 0.0000 <unk> 0.0000 <unk> i 'm using sigmoid threshold units , and i have one input bias node . i run <unk> epochs , and i always get one or two outputs that will not converge . [ here is the matlab code ] ( http : <unk> ) any advice to <unk> a nn would be helpful . thanks , max edit : i found my <unk> . every layer needs a bias unit . [ updated matlab code ] ( http : <unk> ) <unk> <unk> <unk> 0.0000 <unk> 0.0000 <unk> 0.0000 <unk> <unk> <unk> <unk> 0.0000 0.0000 0.0000 <unk> <unk> <unk> <unk> 0.0000 0.0000 0.0000 <unk> <unk> 0.0000 <unk> 0.0000 <unk> <unk> <unk> 0.0000 <unk> <unk> 0.0000 0.0000 <unk> <unk> <unk> <unk> 0.0000 0.0000 0.0000 <unk> <unk> <unk> <unk> <unk> <unk> <unk> 0.0000 <unk> 0.0000 <unk> <unk> <unk> 0.0000 0.0000 <unk> <unk> <unk> 0.0000 <unk> 0.0000 <unk> <eoq> i <unk> my own question : ) <eoa> 
how could i <unk> <unk> with ml ? ( x-post : /r/machinelearning ) x-post from : http : <unk> there is already an ai for playing the game <unk> here . it uses <unk> , but i was wondering about the <unk> of using machine learning to make an ai . how would i set up a neural network or something similar to play the game ? i am not very <unk> with ml , so i 'm looking for advice on how to set up neural network ( nodes per layer ) as well as what algorithms to use for <unk> weights . or maybe neural networks are n't the best approach ? <eoq> i 'm currently working on doing exactly this . did anything come of your project ? <eoa> 
how could i <unk> <unk> with ml ? ( x-post : /r/machinelearning ) x-post from : http : <unk> there is already an ai for playing the game <unk> here . it uses <unk> , but i was wondering about the <unk> of using machine learning to make an ai . how would i set up a neural network or something similar to play the game ? i am not very <unk> with ml , so i 'm looking for advice on how to set up neural network ( nodes per layer ) as well as what algorithms to use for <unk> weights . or maybe neural networks are n't the best approach ? <eoq> i tried an approach with reinforcement learning using a genetic algorithm to <unk> a decision tree forest ( https : <unk> ) . i 'm really not <unk> of my method , and it does n't do better than <unk> . <eoa> 
is there any way to find the <unk> <unk> ' of an audio file ? i have some <unk> <unk> audio that i 'm using for some ml projects . the audio is currently <unk> with a certain <unk> . but , before that , it may have <unk> through a number of other <unk> algorithms . for instance , maybe <unk> for a <unk> <unk> call , then <unk> , then <unk> . etc . is there a way to calculate the how much useful information is still contained in the audio , as compared to a <unk> , ( like say <unk> ) . i do n't have access to the original <unk> files of course . seems like there should be some information <unk> approach that would work ... . <eoq> i 've never worked with this , but my understanding is that useful information is <unk> with <unk> <unk> . http : <unk> # <unk> if i were doing this , i would start with the negative sum over i of p ( <unk> ) * <unk> [ p ( <unk> ) ] <unk> . here are a couple of approaches which do this : http : <unk> http : <unk> and : http : <unk> <eoa> 
pattern recognition : have method , need name . this seems like it might be the best place to post this . i do n't know any of the pattern recognition <unk> in any real <unk> , but i need to know if there is a name for the algorithm in a program i 've already <unk> . if there is n't , then i need to know the <unk> thing to compare it to . i have a simple signal of one variable <unk> another . i fit a number of <unk> at various <unk> in the signal to extract some points , and <unk> the signal by some <unk> simple <unk> which pass through these points . this seems to be something like a <unk> <unk> . i then calculate a few hundred attributes , based on these <unk> for the set of all signals . for instance <unk> of a side or <unk> between two <unk> and so on . i have <unk> by <unk> a subset of these signals into two categories , good or bad . i use this training set to find upper and <unk> <unk> <unk> for these attributes , and apply a boolean test for all the attributes of all the signals using the test set <unk> . in other words finding the <unk> of <unk> ( # of attributes ) that the training set <unk> in and <unk> which <unk> of the <unk> set are within it . this <unk> the output set of good signals for which there are no false <unk> , and very very few false positives ( with these signals <unk> ) . this seems to be something like linear <unk> analysis with hard <unk> instead of dealing with probabilities . i then do various <unk> to find the <unk> set of these <unk> which return the exact same output . this seems to be like feature selection . what do you think ? is there possibly a name for this exact thing <unk> ? have i <unk> close with the <unk> names ? <eoq> your description is a bit too <unk> . you say that > i have a simple signal of one variable <unk> another . which makes it sound like you have 2 variables in <unk> ( i.e , you could plot all of your dataset in a 2d plane ) but the rest of your text <unk> does n't sound like that . i have n't got the <unk> what you mean by `` fitting <unk> at various <unk> in the signal '' , so i 'm just going to <unk> that part and assume that you are dealing with a set of <unk> <unk> , because that 's what it sounds like . then , you obviously totally <unk> training and <unk> ( maybe just a <unk> ) , because <unk> you find some <unk> for some attributes on a <unk> , and then apply a boolean test `` using the <unk> <unk> <unk> '' ? ? ? > this <unk> the output set of good signals for which there are no false <unk> , and very very few false positives ( with these signals <unk> ) . i do n't know why you think there are no false <unk> in that set > this seems to be something like linear <unk> analysis with hard <unk> instead of dealing with probabilities . <unk> not . first of , lda is n't dealing with probabilities either , but more <unk> : what you 're doing sounds nothing like lda . from what i 've <unk> of your method , it is probably most similar to a decision tree . <eoa> 
<unk> and <unk> of <unk> vs <unk> <unk> filtering so let 's say you have a bunch of <unk> users and a bunch of <unk> items . you want to perform <unk> filtering in order to recommend user a a new item . no <unk> is used in any case . i 'm trying to better understand when you 'd do <unk> vs <unk> <unk> filtering . <unk> <unk> filtering makes sense to me - given a user , you match <unk> up with all other users and come up with a <unk> average rating of all <unk> , at which point you can find the most <unk> thing that the user has n't seen yet . what are the <unk> and <unk> of using one vs the other ? if you <unk> the matrix of <unk> , with let 's say users as columns and items as rows , both end up being extremely similar - in <unk> <unk> , you look at <unk> between user columns ( using <unk> similarity or something similar ) , and in <unk> <unk> , you look at <unk> between item rows ( using the same thing ) . what applications make sense for using one vs the other ? <eoq> it seems to me that <unk> or <unk> are just <unk> of each other . in terms of the approach that makes the most sense to me -- clustering -- you would have two <unk> . given <unk> users and <unk> items : * users are a point in <unk> item space , where each of the <unk> <unk> is that user 's rating for the <unk> item * items are a point in <unk> user space , where each of the <unk> <unk> is that item 's rating given by the <unk> user the <unk> lets you find users who are similar to each other based upon their item <unk> , <unk> you to make predictions for the <unk> items by comparing this user to their most similar users and how they <unk> that item , and making the <unk> that similar users will continue to make similar <unk> . i.e . `` here are the users most like you '' , or going <unk> deeper , `` users most similar to you prefer these items '' , or for the <unk> : `` person a is a <unk> ; he is most similar to these people in his <unk> or rating patterns , so check them out as <unk> of interest '' . the <unk> lets you easily find items who are similar to each other based upon their <unk> by users , <unk> you to make predictions for the users who have n't <unk> that item by comparing this item to the most similar items and how the user <unk> that item ( which is just the <unk> of the previous <unk> ) , and making the <unk> that similar items would be <unk> <unk> by similar users . i.e . `` here are the items most similar to this item '' , or going <unk> deeper , `` items similar to this were <unk> by these users '' , or for <unk> <unk> : `` item a is <unk> to be a <unk> <unk> ; these items are most similar based on user <unk> patterns , so <unk> them as <unk> <unk> <unk> as well '' , or perhaps `` item a is a <unk> <unk> ; items similar to this were <unk> by these users , so check them out as <unk> <unk> users '' . <unk> 's just two <unk> of the same <unk> . ** edit : <unk> amazon examples -- they were n't working out for me . : <unk> <eoa> 
are <unk> models of language used for anything <unk> ? i 've <unk> markov models of language before , and they are very <unk> because they can be used to generate <unk> of <unk> <unk> <unk> , but do they have any other uses ? are these models ever <unk> in machine <unk> or speech recognition , or have they been <unk> by something better ? also , i recall there being some kind of markov chain tool in <unk> but i ca n't remember the name . if you know it , please share : ) <eoq> yes , those language <unk> tools essentially sample from an [ <unk> markov model ] ( http : <unk> ) . <eoa> 
are <unk> models of language used for anything <unk> ? i 've <unk> markov models of language before , and they are very <unk> because they can be used to generate <unk> of <unk> <unk> <unk> , but do they have any other uses ? are these models ever <unk> in machine <unk> or speech recognition , or have they been <unk> by something better ? also , i recall there being some kind of markov chain tool in <unk> but i ca n't remember the name . if you know it , please share : ) <eoq> they are used in word prediction . for example , <unk> on <unk> <unk> . there was a really cool <unk> app i saw <unk> ago that could fit in a very small space and <unk> on predicting what you <unk> to type . google search uses them to make suggestions and detect <unk> . i <unk> they might use something like them in google <unk> but i 'm not certain . i do n't know if they are used in speech recognition but it 's <unk> a good application . e.g . is it more likely to user said `` i recognize <unk> '' or `` i recognize <unk> . '' it 's also <unk> possible to use them to get good text <unk> , but i do n't know if anyone actually does that . <eoa> 
<unk> advice wanted . i am trying my hand at a [ <unk> ] ( https : <unk> `` challenge link '' ) challenge . after <unk> after a couple of days that writing my own linear regression in c was going to be <unk> with trouble i decided i would try to use an <unk> from <unk> . after playing with svm <unk> for a couple of minutes i felt like i had a few <unk> worth giving a <unk> . but when i try them on the test data the <unk> plane seems to be fairly <unk> and <unk> the average of all the training values . for more <unk> i am using the <unk> <unk> and experimenting with both the various kernels and <unk> gamma . pointers and links to <unk> to help me better understand what i 'm missing would be most appreciated . thanks . <eoq> what parameters for the <unk> are you using ? its possible you 're <unk> too much . have you <unk> <unk> or mean absolute errors of your cross-validation outputs ? <eoa> 
<unk> advice wanted . i am trying my hand at a [ <unk> ] ( https : <unk> `` challenge link '' ) challenge . after <unk> after a couple of days that writing my own linear regression in c was going to be <unk> with trouble i decided i would try to use an <unk> from <unk> . after playing with svm <unk> for a couple of minutes i felt like i had a few <unk> worth giving a <unk> . but when i try them on the test data the <unk> plane seems to be fairly <unk> and <unk> the average of all the training values . for more <unk> i am using the <unk> <unk> and experimenting with both the various kernels and <unk> gamma . pointers and links to <unk> to help me better understand what i 'm missing would be most appreciated . thanks . <eoq> just <unk> to let any <unk> by know that it was a <unk> of <unk> to solve this problem with scikit-learn . the <unk> part was using python with nearly no previous experience . if scikit-learn <unk> to be this <unk> i look forward to being very <unk> for the <unk> . for now consider this problem <unk> . <eoa> 
why is machine learning important and how is it applied in business ? background : i am an business <unk> . my analysis to this point has been <unk> <unk> to <unk> and access , with some use of business <unk> and <unk> . in my <unk> life , i am learning more about computer science and <unk> python . my degree was in <unk> and <unk> <unk> . complete ml noob . <eoq> it <unk> more difficult to see <unk> , and to make <unk> decisions from data , when the amount of data <unk> <unk> what a person or team of people can handle . in order to make the most of a large amount of data , it is necessary to <unk> the <unk> we use to <unk> , and make decisions from it . <eoa> 
why is machine learning important and how is it applied in business ? background : i am an business <unk> . my analysis to this point has been <unk> <unk> to <unk> and access , with some use of business <unk> and <unk> . in my <unk> life , i am learning more about computer science and <unk> python . my degree was in <unk> and <unk> <unk> . complete ml noob . <eoq> i 'm not sure what <unk> of business you 're in , but i know <unk> uses a lot of machine learning . consider the idea of <unk> prediction . say you want to predict the <unk> price at the end of the day . what types of information may be useful ? the price at the previous day would be useful , the price the day before would be as well . <unk> in similar <unk> may also be useful . you can then use these pieces of information together to build a <unk> model of what the <unk> price at the end of the day will be . in general more information is used as well and i can get you some links for that if you would be interested . <eoa> 
