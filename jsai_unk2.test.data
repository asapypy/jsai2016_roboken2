would anyone be willing to look over my simple nn octave code ? i 'm currently taking the stanford ml course on coursera and have been more or less <unk> through all the programming assignments . this includes neural networks and the back-propagation algorithm . however , i tried <unk> it on my own from memory and i just ca n't get it to work right . first i tried in java , then in octave , and i 'm getting similar results - a bit of learning at first and then it <unk> off at a low success percentage . obviously something is wrong ( probably in my back-propagation algorithm ) , but i 've been over and over it and ca n't figure out what . there are no errors when i run the code , but i 'm thinking it has to be something obvious that i 'm overlooking . would anyone be willing to take a look at some <unk> <unk> octave code to see if anything looks wrong ? code is [ here ] ( https : <unk> ) . <eoq> if you still need to <unk> it , have a look at : http : <unk> <unk> <eoa> 
problem : simulate a <unk> device that outputs numbers from <unk> . so i <unk> recently gotten into statistical modeling and this problem <unk> into my head . so here s the rest of the setup : the device outputs a list like : <unk> , <unk> , 32 without <unk> and no <unk> so <unk> to my <unk> this can be thought of as the <unk> <unk> and <unk> model and so the whole theory of hidden markov models can be used to develop a solution to this problem . so what i 'd like is <unk> that yes i m on the right track with a solution to this and also what software should i use to actually try and solve this . <eoq> when i first read your problem i thought of hidden markov models . another approach may be recurrent neural networks . <eoa> 
common mistakes for beginners ? my ann is <unk> <unk> . i 'm getting into machine learning , and tried implementing a neural net in java based off of [ this ] ( http : <unk> ) online book . i 've tested two different training scenarios - one was simply adding two numbers between 0 and 9 together , and the other was <unk> handwritten digits from the mnist data set . the problem is convergence is slow and <unk> out at a fairly low level ( <unk> % correct answers for addition and <unk> % for mnist data ) . it 's obviously working somewhat because i 'm getting more correct answers than i would by chance alone , but i feel like i should be getting a lot more . the addition problem is easy and the book shows a python implementation getting over 90 % correct after a single training epoch . <unk> learning rate and <unk> of hidden layers has n't helped much ( also i feel like i need to have a pretty high learning rate for things to get anywhere , like <unk> ) . i 've been over and over my backpropagation algorithm many times and ca n't find any mistakes . is there anything obvious i may have <unk> or should <unk> ? any help would be much appreciated . <eoq> you may want to try the ufldl tutorial 's technique for checking your feed-forward network code : <eoa> 
common mistakes for beginners ? my ann is <unk> <unk> . i 'm getting into machine learning , and tried implementing a neural net in java based off of [ this ] ( http : <unk> ) online book . i 've tested two different training scenarios - one was simply adding two numbers between 0 and 9 together , and the other was <unk> handwritten digits from the mnist data set . the problem is convergence is slow and <unk> out at a fairly low level ( <unk> % correct answers for addition and <unk> % for mnist data ) . it 's obviously working somewhat because i 'm getting more correct answers than i would by chance alone , but i feel like i should be getting a lot more . the addition problem is easy and the book shows a python implementation getting over 90 % correct after a single training epoch . <unk> learning rate and <unk> of hidden layers has n't helped much ( also i feel like i need to have a pretty high learning rate for things to get anywhere , like <unk> ) . i 've been over and over my backpropagation algorithm many times and ca n't find any mistakes . is there anything obvious i may have <unk> or should <unk> ? any help would be much appreciated . <eoq> you should be getting a lot more . if you are doing the same number of iterations as that online book , you should be getting the same results . for a similar architecture , you can get up to <unk> % accuracy on mnist ( eg http : <unk> ) . you clearly have a bug . i would write unit tests for the pieces until you find it . good luck ! <eoa> 
the <unk> course was my favorite <eoa> 
i think the [ unsupervised feature learning and deep learning tutorial ] ( http : <unk> ) is a good follow up . <eoa> 
study note <unk> hi <unk> . should start out by saying that i am new to ml . i have a strong background in stats and calculus , but none in programming ( i 'll be taking the coursera class in programming this <unk> ) . for a while now , i 've had an idea for a program thats been <unk> around in my head . specifically , i want to create a program that takes text ( likely in <unk> or <unk> <unk> ) and convert it into a series of questions and answers . for example , given the following : > <unk> the capital of canada is <unk> . > <unk> into <unk> & a <unk> <unk> : what is the capital of canada ? a : what capital of canada is <unk> . any suggestions for starting this would be greatly appreciated . i know there are a lot of courses out there , but if someone could <unk> down what areas i should focus on , then i could take a <unk> approach to learning about what i need to know . thanks ! <eoq> two quick <unk> . first , you would probably want to deal with raw text rather than <unk> <unk> . there are tools to extract text from <unk> and pdf files , but they are error <unk> . second , this is n't so much a machine learning task as it is a syntax task . see any good <unk> <unk> on the topic of <unk> <unk> , and you 'll see that there 's most likely a simple <unk> solution to this problem . <eoa> 
difficulty training simple xor function . i 've created a neural network , with the following structure : input1 - input2 - **input layer** . n0 - n1 - **hidden layer** . 3 weights per node ( one for bias ) . n2 - **output layer** . 3 weights ( one for bias ) . i am trying to train it the xor function with the following test data : * **0 1** - desired result : **1** * **1 0** - desired result : **1** * **0 0** - desired result : **0** * **1 1** - desired result : **0** after training , the **mean square error** of test ( when looking for a 1 result ) { 0 , 1 } = 0 , which is good i presume . however the mean square error of test ( when looking for a 0 result ) { 1 , 1 } = 0.5 , which surely needs to be zero ? during the train stage i notice the mse of true results drops to zero very quickly , whereas mse of false results lingers around 0.5 . i 'm using back propagation to train the network , with a sigmoid function . the issue is that when i test any combination after the training , i get a ouput result of **1.000014 for true** , and **1.000104 for false** . i 'm trying to get 1 for true , 0 for false . the network seems to learn very fast , even with an extremely small learning rate . if it helps , here is the weights that are produced , with a learning rate of **0.1** : n0-w0 = **-0.999** , n0-w1 = **0.655** , n0-w2 = **0.304** ( **bias weight** ) - hidden layer n1-w0 = **0.674** , n1-w1 = **-0.893** , n1-w2 = **0.516** ( **bias weight** ) - hidden layer n2-w0 = **2.135** , n2-w1 = **2.442** , n3-w2 = **1.543** ( **bias weight** ) - output node back propagation steps : 1 . **feed forward a feature set , summing the weights x input set . calculating sigmoid per node . ** 2 . **apply bias . ** 3 . **calculate output node error , desired output - actual output ( sigmoid ) . ** 4 . **back propagate error , layer above error x connecting weight . per node . ** 5 . **adjust weights , repeat till mse low enough . ** apologies for the long post , but i 've been scratching my header over this for awhile now , and i ca n't determine what is wrong with my back propagation algorithm . thanks in advance . <eoq> can you show me your code ? its <unk> what order you 're doing some of the steps in the feed-forward process . and also you need to <unk> through the whole network . <eoa> 
difficulty training simple xor function . i 've created a neural network , with the following structure : input1 - input2 - **input layer** . n0 - n1 - **hidden layer** . 3 weights per node ( one for bias ) . n2 - **output layer** . 3 weights ( one for bias ) . i am trying to train it the xor function with the following test data : * **0 1** - desired result : **1** * **1 0** - desired result : **1** * **0 0** - desired result : **0** * **1 1** - desired result : **0** after training , the **mean square error** of test ( when looking for a 1 result ) { 0 , 1 } = 0 , which is good i presume . however the mean square error of test ( when looking for a 0 result ) { 1 , 1 } = 0.5 , which surely needs to be zero ? during the train stage i notice the mse of true results drops to zero very quickly , whereas mse of false results lingers around 0.5 . i 'm using back propagation to train the network , with a sigmoid function . the issue is that when i test any combination after the training , i get a ouput result of **1.000014 for true** , and **1.000104 for false** . i 'm trying to get 1 for true , 0 for false . the network seems to learn very fast , even with an extremely small learning rate . if it helps , here is the weights that are produced , with a learning rate of **0.1** : n0-w0 = **-0.999** , n0-w1 = **0.655** , n0-w2 = **0.304** ( **bias weight** ) - hidden layer n1-w0 = **0.674** , n1-w1 = **-0.893** , n1-w2 = **0.516** ( **bias weight** ) - hidden layer n2-w0 = **2.135** , n2-w1 = **2.442** , n3-w2 = **1.543** ( **bias weight** ) - output node back propagation steps : 1 . **feed forward a feature set , summing the weights x input set . calculating sigmoid per node . ** 2 . **apply bias . ** 3 . **calculate output node error , desired output - actual output ( sigmoid ) . ** 4 . **back propagate error , layer above error x connecting weight . per node . ** 5 . **adjust weights , repeat till mse low enough . ** apologies for the long post , but i 've been scratching my header over this for awhile now , and i ca n't determine what is wrong with my back propagation algorithm . thanks in advance . <eoq> the bias is just another input to the neuron . do n't treat it special ( besides always getting an input value = 1 ) . also , does your code work for the or and and cases ? <eoa> 
difficulty training simple xor function . i 've created a neural network , with the following structure : input1 - input2 - **input layer** . n0 - n1 - **hidden layer** . 3 weights per node ( one for bias ) . n2 - **output layer** . 3 weights ( one for bias ) . i am trying to train it the xor function with the following test data : * **0 1** - desired result : **1** * **1 0** - desired result : **1** * **0 0** - desired result : **0** * **1 1** - desired result : **0** after training , the **mean square error** of test ( when looking for a 1 result ) { 0 , 1 } = 0 , which is good i presume . however the mean square error of test ( when looking for a 0 result ) { 1 , 1 } = 0.5 , which surely needs to be zero ? during the train stage i notice the mse of true results drops to zero very quickly , whereas mse of false results lingers around 0.5 . i 'm using back propagation to train the network , with a sigmoid function . the issue is that when i test any combination after the training , i get a ouput result of **1.000014 for true** , and **1.000104 for false** . i 'm trying to get 1 for true , 0 for false . the network seems to learn very fast , even with an extremely small learning rate . if it helps , here is the weights that are produced , with a learning rate of **0.1** : n0-w0 = **-0.999** , n0-w1 = **0.655** , n0-w2 = **0.304** ( **bias weight** ) - hidden layer n1-w0 = **0.674** , n1-w1 = **-0.893** , n1-w2 = **0.516** ( **bias weight** ) - hidden layer n2-w0 = **2.135** , n2-w1 = **2.442** , n3-w2 = **1.543** ( **bias weight** ) - output node back propagation steps : 1 . **feed forward a feature set , summing the weights x input set . calculating sigmoid per node . ** 2 . **apply bias . ** 3 . **calculate output node error , desired output - actual output ( sigmoid ) . ** 4 . **back propagate error , layer above error x connecting weight . per node . ** 5 . **adjust weights , repeat till mse low enough . ** apologies for the long post , but i 've been scratching my header over this for awhile now , and i ca n't determine what is wrong with my back propagation algorithm . thanks in advance . <eoq> i just ran xor on a <unk> nn and got these weights h1 h2 <unk> <unk> <unk> <unk> weight <unk> <unk> <unk> //weight to input 1 <unk> <unk> <unk> //weight to input 2 <unk> <unk> <unk> <unk> weight <unk> <unk> //weight to h1 <unk> <unk> //weight to h2 throw these numbers into your code to see if your forward propagation code works . results that i get using sigmoid units are : <unk> // result for 0 0 <unk> // result for 0 1 <unk> // result for 1 0 <unk> // result for 1 1 <eoa> 
neural network learning fast , giving me false positives . i 've recently started implementing a feed-forward neural network and i 'm using back-propagation as the learning method . i 've been using http : //galaxy.agh.edu.pl/~vlsi/ai/backp_t_en/backprop.html as a guide . however , after just the first epoch , my **error is 0** . before using the network for my real purpose i 've tried with the simple network structure : * 4 binary inputs , 1 , 1 , 0 , 0 . * 2 hidden layers , 4 neurons each . * 1 output neuron , 1.0 should = valid input . each training epoch runs the test input ( 1 , 1 , 0 , 0 ) , calculates the output error ( sigmoid derivative * ( 1.0 - sigmoid ) ) , back propagates the error and finally adjusts the weights . each neuron 's new weight = **weight + learning_rate * the neuron 's error * the input to the weight . ** each hidden neuron 's error = ** ( sum of all output neuron 's error * connected weight ) * the neuron 's sigmoid derivative . ** the issue is that my **learning rate has to be 0.0001** for me to see any sort of 'progress ' between the epochs in terms of lowering the error . in this case , the error starts around ~30.0 . any greater learning rate and the error results in 0 after the first pass , and thus results in **false positives** . also when i try this network with my real data ( a set of 32 audio features from sample - 32 neurons per hidden layer ) - i get the same issue . to the point where any noise will trigger a false positive . possibly this could be an input feature issue , but as i 'm testing using a high pitch note i can clearly see the raw data differs from a low pitch one . i 'm a neural networks newbie , so i 'm almost positive the issue is with my network . any help would be greatly appreciated . <eoq> i really do n't know enough to say for sure but it sounds like you are just overfitting . nns are very good at that . try using a smaller network or some other <unk> method . <eoa> 
neural network learning fast , giving me false positives . i 've recently started implementing a feed-forward neural network and i 'm using back-propagation as the learning method . i 've been using http : //galaxy.agh.edu.pl/~vlsi/ai/backp_t_en/backprop.html as a guide . however , after just the first epoch , my **error is 0** . before using the network for my real purpose i 've tried with the simple network structure : * 4 binary inputs , 1 , 1 , 0 , 0 . * 2 hidden layers , 4 neurons each . * 1 output neuron , 1.0 should = valid input . each training epoch runs the test input ( 1 , 1 , 0 , 0 ) , calculates the output error ( sigmoid derivative * ( 1.0 - sigmoid ) ) , back propagates the error and finally adjusts the weights . each neuron 's new weight = **weight + learning_rate * the neuron 's error * the input to the weight . ** each hidden neuron 's error = ** ( sum of all output neuron 's error * connected weight ) * the neuron 's sigmoid derivative . ** the issue is that my **learning rate has to be 0.0001** for me to see any sort of 'progress ' between the epochs in terms of lowering the error . in this case , the error starts around ~30.0 . any greater learning rate and the error results in 0 after the first pass , and thus results in **false positives** . also when i try this network with my real data ( a set of 32 audio features from sample - 32 neurons per hidden layer ) - i get the same issue . to the point where any noise will trigger a false positive . possibly this could be an input feature issue , but as i 'm testing using a high pitch note i can clearly see the raw data differs from a low pitch one . i 'm a neural networks newbie , so i 'm almost positive the issue is with my network . any help would be greatly appreciated . <eoq> <unk> your initial weights . i 've had good results with random numbers between +/- 0.5 <eoa> 
neural network learning fast , giving me false positives . i 've recently started implementing a feed-forward neural network and i 'm using back-propagation as the learning method . i 've been using http : //galaxy.agh.edu.pl/~vlsi/ai/backp_t_en/backprop.html as a guide . however , after just the first epoch , my **error is 0** . before using the network for my real purpose i 've tried with the simple network structure : * 4 binary inputs , 1 , 1 , 0 , 0 . * 2 hidden layers , 4 neurons each . * 1 output neuron , 1.0 should = valid input . each training epoch runs the test input ( 1 , 1 , 0 , 0 ) , calculates the output error ( sigmoid derivative * ( 1.0 - sigmoid ) ) , back propagates the error and finally adjusts the weights . each neuron 's new weight = **weight + learning_rate * the neuron 's error * the input to the weight . ** each hidden neuron 's error = ** ( sum of all output neuron 's error * connected weight ) * the neuron 's sigmoid derivative . ** the issue is that my **learning rate has to be 0.0001** for me to see any sort of 'progress ' between the epochs in terms of lowering the error . in this case , the error starts around ~30.0 . any greater learning rate and the error results in 0 after the first pass , and thus results in **false positives** . also when i try this network with my real data ( a set of 32 audio features from sample - 32 neurons per hidden layer ) - i get the same issue . to the point where any noise will trigger a false positive . possibly this could be an input feature issue , but as i 'm testing using a high pitch note i can clearly see the raw data differs from a low pitch one . i 'm a neural networks newbie , so i 'm almost positive the issue is with my network . any help would be greatly appreciated . <eoq> sounds like it 's overfitting the training data ... have you tried adding a regularization term to your cost function ? <eoa> 
how much data do you need to do ml ? i 'm personally most familiar with split testing on websites . but to really do some ml , what kind of data sets do you need ? <eoq> the <unk> answer is that it depends . the more complicated your model is the more data you need in order to avoid <unk> . i 've [ read ] ( http : <unk> ? <unk> & <unk> & <unk> & <unk> ) that a good rule of thumb for a supervised linear model is ten training examples for every parameter of the model . it is my understanding that linear models are generally considered relatively simple models so that number should probably increase for other sorts of models . <eoa> 
<unk> neural network does not converge . hello , i 'm trying to recreate the <unk> neural network . i 'm having trouble getting my network to converge . it 'll get close , but there is always one output that wo n't converge . for example : output = <unk> 0.0000 <unk> 0.0000 0.0000 <unk> 0.0002 0.0002 0.0000 <unk> <unk> 0.0000 0.0000 <unk> 0.0000 0.0000 <unk> 0.0002 <unk> 0.0000 <unk> <unk> 0.0000 0.0000 0.0000 0.0001 0.0000 <unk> 0.0000 <unk> 0.0000 0.0000 0.0000 0.0000 <unk> 0.0001 <unk> <unk> 0.0000 0.0000 <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> <unk> 0.0000 0.0000 0.0000 0.0000 <unk> <unk> 0.0000 <unk> 0.0000 0.0000 0.0000 0.0000 <unk> 0.0000 <unk> i 'm using sigmoid threshold units , and i have one input bias node . i run <unk> epochs , and i always get one or two outputs that will not converge . [ here is the matlab code ] ( http : <unk> ) any advice to <unk> a nn would be helpful . thanks , max edit : i found my mistake . every layer needs a bias unit . [ updated matlab code ] ( http : <unk> ) <unk> <unk> <unk> 0.0000 <unk> 0.0000 <unk> 0.0000 <unk> <unk> <unk> <unk> 0.0000 0.0000 0.0000 <unk> <unk> <unk> <unk> 0.0000 0.0000 0.0000 <unk> <unk> 0.0000 <unk> 0.0000 <unk> <unk> 0.0002 0.0000 <unk> <unk> 0.0000 0.0000 <unk> <unk> <unk> <unk> 0.0000 0.0000 0.0000 0.0001 <unk> <unk> <unk> <unk> <unk> <unk> 0.0000 <unk> 0.0000 <unk> <unk> <unk> 0.0000 0.0000 <unk> <unk> <unk> 0.0000 <unk> 0.0000 <unk> <eoq> i <unk> my own question : ) <eoa> 
how could i <unk> 2048 with ml ? ( x-post : /r/machinelearning ) x-post from : http : <unk> there is already an ai for playing the game 2048 here . it uses <unk> , but i was wondering about the <unk> of using machine learning to make an ai . how would i set up a neural network or something similar to play the game ? i am not very experienced with ml , so i 'm looking for advice on how to set up neural network ( nodes per layer ) as well as what algorithms to use for <unk> weights . or maybe neural networks are n't the best approach ? <eoq> i 'm currently working on doing exactly this . did anything come of your project ? <eoa> 
how could i <unk> 2048 with ml ? ( x-post : /r/machinelearning ) x-post from : http : <unk> there is already an ai for playing the game 2048 here . it uses <unk> , but i was wondering about the <unk> of using machine learning to make an ai . how would i set up a neural network or something similar to play the game ? i am not very experienced with ml , so i 'm looking for advice on how to set up neural network ( nodes per layer ) as well as what algorithms to use for <unk> weights . or maybe neural networks are n't the best approach ? <eoq> i tried an approach with reinforcement learning using a genetic algorithm to <unk> a decision tree forest ( https : <unk> ) . i 'm really not <unk> of my method , and it does n't do better than <unk> . <eoa> 
is there any way to find the <unk> <unk> ' of an audio file ? i have some <unk> recorded audio that i 'm using for some ml projects . the audio is currently <unk> with a certain <unk> . but , before that , it may have gone through a number of other <unk> algorithms . for instance , maybe <unk> for a cell phone call , then <unk> , then <unk> . etc . is there a way to calculate the how much useful information is still contained in the audio , as compared to a reference , ( like say <unk> ) . i do n't have access to the original <unk> files of course . seems like there should be some information <unk> approach that would work ... . <eoq> i 've never worked with this , but my understanding is that useful information is <unk> with <unk> entropy . http : <unk> # <unk> if i were doing this , i would start with the negative sum over i of p ( <unk> ) * <unk> [ p ( <unk> ) ] expression . here are a couple of approaches which do this : http : <unk> http : <unk> and : http : <unk> <eoa> 
pattern recognition : have method , need name . this seems like it might be the best place to post this . i do n't know any of the pattern recognition <unk> in any real depth , but i need to know if there is a name for the algorithm in a program i 've already finished . if there is n't , then i need to know the closest thing to compare it to . i have a simple signal of one variable vs. another . i fit a number of <unk> at various places in the signal to extract some points , and <unk> the signal by some <unk> simple shapes which pass through these points . this seems to be something like a <unk> transform . i then calculate a few hundred attributes , based on these shapes for the set of all signals . for instance length of a side or angle between two sides and so on . i have <unk> by <unk> a subset of these signals into two categories , good or bad . i use this training set to find upper and lower limits <unk> for these attributes , and apply a boolean test for all the attributes of all the signals using the test set limits . in other words finding the <unk> of dimension ( # of attributes ) that the training set <unk> in and reporting which events of the total set are within it . this defines the output set of good signals for which there are no false negatives , and very very few false positives ( with these signals anyhow ) . this seems to be something like linear <unk> analysis with hard limits instead of dealing with probabilities . i then do various operations to find the <unk> set of these <unk> which return the exact same output . this seems to be like feature selection . what do you think ? is there possibly a name for this exact thing <unk> ? have i gotten close with the <unk> names ? <eoq> your description is a bit too <unk> . you say that > i have a simple signal of one variable vs. another . which makes it sound like you have 2 variables in total ( i.e , you could plot all of your dataset in a 2d plane ) but the rest of your text absolutely does n't sound like that . i have n't got the <unk> what you mean by `` fitting <unk> at various places in the signal '' , so i 'm just going to <unk> that part and assume that you are dealing with a set of <unk> shapes , because that 's what it sounds like . then , you obviously totally <unk> training and <unk> ( maybe just a <unk> ) , because apparently you find some <unk> for some attributes on a <unk> , and then apply a boolean test `` using the <unk> <unk> limits '' ? ? ? > this defines the output set of good signals for which there are no false negatives , and very very few false positives ( with these signals anyhow ) . i do n't know why you think there are no false negatives in that set > this seems to be something like linear <unk> analysis with hard limits instead of dealing with probabilities . absolutely not . first of , lda is n't dealing with probabilities either , but more <unk> : what you 're doing sounds nothing like lda . from what i 've understood of your method , it is probably most similar to a decision tree . <eoa> 
pros and cons of user-based vs item-based collaborative filtering so let 's say you have a bunch of <unk> users and a bunch of <unk> items . you want to perform collaborative filtering in order to recommend user a a new item . no <unk> is used in any case . i 'm trying to better understand when you 'd do user-based vs item-based collaborative filtering . user-based collaborative filtering makes sense to me - given a user , you match <unk> up with all other users and come up with a <unk> average rating of all songs , at which point you can find the most <unk> thing that the user has n't seen yet . what are the pros and cons of using one vs the other ? if you construct the matrix of ratings , with let 's say users as columns and items as rows , both end up being extremely similar - in user-based <unk> , you look at correlations between user columns ( using <unk> similarity or something similar ) , and in item-based <unk> , you look at correlations between item rows ( using the same thing ) . what applications make sense for using one vs the other ? <eoq> it seems to me that user-based or item-based are just <unk> of each other . in terms of the approach that makes the most sense to me -- clustering -- you would have two <unk> . given <unk> users and <unk> items : * users are a point in <unk> item space , where each of the <unk> dimensions is that user 's rating for the <unk> item * items are a point in <unk> user space , where each of the <unk> dimensions is that item 's rating given by the <unk> user the <unk> lets you find users who are similar to each other based upon their item ratings , <unk> you to make predictions for the <unk> items by comparing this user to their most similar users and how they rated that item , and making the assumption that similar users will continue to make similar ratings . i.e . `` here are the users most like you '' , or going <unk> deeper , `` users most similar to you prefer these items '' , or for the <unk> : `` person a is a <unk> ; he is most similar to these people in his buying or rating patterns , so check them out as persons of interest '' . the latter lets you easily find items who are similar to each other based upon their ratings by users , <unk> you to make predictions for the users who have n't rated that item by comparing this item to the most similar items and how the user rated that item ( which is just the <unk> of the previous <unk> ) , and making the assumption that similar items would be ranked <unk> by similar users . i.e . `` here are the items most similar to this item '' , or going <unk> deeper , `` items similar to this were bought by these users '' , or for <unk> <unk> : `` item a is <unk> to be a mind-altering <unk> ; these items are most similar based on user buying patterns , so investigate them as potential mind-altering <unk> as well '' , or perhaps `` item a is a mind-altering <unk> ; items similar to this were bought by these users , so check them out as potential <unk> users '' . <unk> 's just two sides of the same <unk> . ** edit : removed amazon examples -- they were n't working out for me . : <unk> <eoa> 
are <unk> models of language used for anything <unk> ? i 've <unk> markov models of language before , and they are very <unk> because they can be used to generate sequences of realistic <unk> <unk> , but do they have any other uses ? are these models ever <unk> in machine <unk> or speech recognition , or have they been <unk> by something better ? also , i recall there being some kind of markov chain tool in ubuntu but i ca n't remember the name . if you know it , please share : ) <eoq> yes , those language <unk> tools essentially sample from an [ <unk> markov model ] ( http : <unk> ) . <eoa> 
are <unk> models of language used for anything <unk> ? i 've <unk> markov models of language before , and they are very <unk> because they can be used to generate sequences of realistic <unk> <unk> , but do they have any other uses ? are these models ever <unk> in machine <unk> or speech recognition , or have they been <unk> by something better ? also , i recall there being some kind of markov chain tool in ubuntu but i ca n't remember the name . if you know it , please share : ) <eoq> they are used in word prediction . for example , <unk> on mobile <unk> . there was a really cool <unk> app i saw awhile ago that could fit in a very small space and <unk> on predicting what you meant to type . google search uses them to make suggestions and detect <unk> . i <unk> they might use something like them in google <unk> but i 'm not certain . i do n't know if they are used in speech recognition but it 's <unk> a good application . e.g . is it more likely to user said `` i recognize <unk> '' or `` i recognize <unk> . '' it 's also <unk> possible to use them to get good text <unk> , but i do n't know if anyone actually does that . <eoa> 
svr advice wanted . i am trying my hand at a [ <unk> ] ( https : <unk> `` challenge link '' ) challenge . after determining after a couple of days that writing my own linear regression in c was going to be <unk> with trouble i decided i would try to use an svr from libsvm . after playing with svm <unk> for a couple of minutes i felt like i had a few <unk> worth giving a <unk> . but when i try them on the test data the resulting plane seems to be fairly horizontal and near the average of all the training values . for more specifics i am using the libsvm nu-svr and experimenting with both the various kernels and <unk> gamma . pointers and links to <unk> to help me better understand what i 'm missing would be most appreciated . thanks . <eoq> what parameters for the nu-svr are you using ? its possible you 're <unk> too much . have you gotten <unk> or mean absolute errors of your cross-validation outputs ? <eoa> 
svr advice wanted . i am trying my hand at a [ <unk> ] ( https : <unk> `` challenge link '' ) challenge . after determining after a couple of days that writing my own linear regression in c was going to be <unk> with trouble i decided i would try to use an svr from libsvm . after playing with svm <unk> for a couple of minutes i felt like i had a few <unk> worth giving a <unk> . but when i try them on the test data the resulting plane seems to be fairly horizontal and near the average of all the training values . for more specifics i am using the libsvm nu-svr and experimenting with both the various kernels and <unk> gamma . pointers and links to <unk> to help me better understand what i 'm missing would be most appreciated . thanks . <eoq> just <unk> to let any <unk> by know that it was a piece of <unk> to solve this problem with scikit-learn . the <unk> part was using python with nearly no previous experience . if scikit-learn continues to be this <unk> i look forward to being very <unk> for the recommendation . for now consider this problem solved . <eoa> 
why is machine learning important and how is it applied in business ? background : i am an business <unk> . my analysis to this point has been mainly restricted to <unk> and access , with some use of business objects and sql . in my personal life , i am learning more about computer science and practicing python . my degree was in <unk> and <unk> <unk> . complete ml noob . <eoq> it becomes more difficult to see trends , and to make <unk> decisions from data , when the amount of data <unk> beyond what a person or team of people can handle . in order to make the most of a large amount of data , it is necessary to automate the processes we use to <unk> , and make decisions from it . <eoa> 
why is machine learning important and how is it applied in business ? background : i am an business <unk> . my analysis to this point has been mainly restricted to <unk> and access , with some use of business objects and sql . in my personal life , i am learning more about computer science and practicing python . my degree was in <unk> and <unk> <unk> . complete ml noob . <eoq> i 'm not sure what <unk> of business you 're in , but i know <unk> uses a lot of machine learning . consider the idea of stock prediction . say you want to predict the stock price at the end of the day . what types of information may be useful ? the price at the previous day would be useful , the price the day before would be as well . <unk> in similar industries may also be useful . you can then use these pieces of information together to build a predictive model of what the stock price at the end of the day will be . in general more information is used as well and i can get you some links for that if you would be interested . <eoa> 
